(.venv) ludovic@ludovic-HP-ProBook-450-G7:~/Test_Lab/machine_learning_security/DeepExploit$ python3 DeepExploit.py -t 172.16.1.2 -m test
2021-03-30 15:55:44.592675: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-03-30 15:55:44.592694: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Using TensorFlow backend.

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 ██████╗ ███████╗███████╗██████╗     ███████╗██╗  ██╗██████╗ ██╗      ██████╗ ██╗████████╗
 ██╔══██╗██╔════╝██╔════╝██╔══██╗    ██╔════╝╚██╗██╔╝██╔══██╗██║     ██╔═══██╗██║╚══██╔══╝
 ██║  ██║█████╗  █████╗  ██████╔╝    █████╗   ╚███╔╝ ██████╔╝██║     ██║   ██║██║   ██║   
 ██║  ██║██╔══╝  ██╔══╝  ██╔═══╝     ██╔══╝   ██╔██╗ ██╔═══╝ ██║     ██║   ██║██║   ██║   
 ██████╔╝███████╗███████╗██║         ███████╗██╔╝ ██╗██║     ███████╗╚██████╔╝██║   ██║   
 ╚═════╝ ╚══════╝╚══════╝╚═╝         ╚══════╝╚═╝  ╚═╝╚═╝     ╚══════╝ ╚═════╝ ╚═╝   ╚═╝   (beta)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    

       =[ Deep Exploit v0.0.2-beta                                            ]=
+ -- --=[ Author  : Isao Takaesu (@bbr_bbq)                                   ]=--
+ -- --=[ Website : https://github.com/13o-bbr-bbq/machine_learning_security/ ]=--
    
[+] Execute Nmap against 172.16.1.2
[*] nmap -p0-65535 -T5 -Pn -sV -sT --min-rate 1000 -oX nmap_result_172.16.1.2.xml 172.16.1.2

[*] Start time: 2021/03/30 15:55:45
[*] Port scanning: 172.16.1.2 [Elapsed time: 0 s]
[*] Executing keep_alive..
[*] End time  : 2021/03/30 15:55:49
[+] Get port list from nmap_result_172.16.1.2.xml.
[*] Getting 21/tcp info: Microsoft ftpd 
[*] Getting 22/tcp info: OpenSSH 7.1 protocol 2.0
[*] Getting 80/tcp info: Microsoft IIS httpd 7.5 
[*] Getting 135/tcp info: Microsoft Windows RPC 
[*] Getting 139/tcp info: Microsoft Windows netbios-ssn 
[*] Getting 445/tcp info: Microsoft Windows Server 2008 R2 - 2012 microsoft-ds 
[*] Getting 1617/tcp info: Java RMI 
[*] Getting 3306/tcp info: MySQL 5.5.20-log 
[*] Getting 3389/tcp info: unknown
[*] Getting 3700/tcp info: CORBA naming service 
[*] Getting 3820/tcp info: unknown
[*] Getting 4848/tcp info: unknown
[*] Getting 5985/tcp info: Microsoft HTTPAPI httpd 2.0 SSDP/UPnP
[*] Getting 7676/tcp info: Java Message Service 301 
[*] Getting 8009/tcp info: Apache Jserv Protocol v1.3
[*] Getting 8019/tcp info: unknown
[*] Getting 8020/tcp info: Apache httpd 
[*] Getting 8022/tcp info: Apache Tomcat/Coyote JSP engine 1.1 
[*] Getting 8027/tcp info: unknown
[*] Getting 8028/tcp info: PostgreSQL DB 
[*] Getting 8031/tcp info: unknown
[*] Getting 8032/tcp info: ManageEngine Desktop Central DesktopCentralServer 
[*] Getting 8080/tcp info: Sun GlassFish Open Source Edition  4.0 
[*] Getting 8181/tcp info: unknown
[*] Getting 8282/tcp info: Apache Tomcat/Coyote JSP engine 1.1 
[*] Getting 8383/tcp info: Apache httpd 
[*] Getting 8443/tcp info: unknown
[*] Getting 8444/tcp info: ManageEngine Desktop Central DesktopCentralServer 
[*] Getting 8484/tcp info: Jetty winstone-2.8 
[*] Getting 8585/tcp info: Apache httpd 2.2.21 (Win64) PHP/5.3.10 DAV/2
[*] Getting 8686/tcp info: Java RMI 
[*] Getting 9200/tcp info: unknown
[*] Getting 9300/tcp info: unknown
[*] Getting 31337/tcp info: unknown
[*] Getting 47001/tcp info: Microsoft HTTPAPI httpd 2.0 SSDP/UPnP
[*] Getting 49152/tcp info: Microsoft Windows RPC 
[*] Getting 49153/tcp info: Microsoft Windows RPC 
[*] Getting 49154/tcp info: Microsoft Windows RPC 
[*] Getting 49155/tcp info: Microsoft Windows RPC 
[*] Getting 49156/tcp info: unknown
[*] Getting 49169/tcp info: Java RMI 
[*] Getting 49170/tcp info: unknown
[*] Getting 49227/tcp info: Microsoft Windows RPC 
[*] Getting 49228/tcp info: Microsoft Windows RPC 
[*] Getting 49237/tcp info: Apache Mina sshd 0.8.0 protocol 2.0
[*] Getting 49239/tcp info: Jenkins TcpSlaveAgentListener 
[*] Getting 58345/tcp info: Java RMI 
[*] Getting 58348/tcp info: unknown
[*] Getting 58349/tcp info: unknown
[*] Getting 58350/tcp info: unknown
[+] Get exploit list.
[*] Loaded exploit list from : /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/data/exploit_list.csv
[+] Get payload list.
[*] Loaded payload list from : /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/data/payload_list.csv
[+] Get exploit tree.
[*] Loaded exploit tree from : /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/data/exploit_tree.json
> /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/DeepExploit.py(2347)<module>()
-> com_indicate_flag = check_port_value(port, service)
(Pdb) c
[+] Get target info.
[+] Check web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:21
c[!] Port "21" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:21                                                                                                                                                                                           [!] Port "21" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:22
[!] Port "22" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:22
[!] Port "22" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:80
[*] Port "80" is web port. status=200
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:135
[!] Port "135" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:135
[!] Port "135" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:139
[!] Port "139" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:139
[!] Port "139" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:445
[!] Port "445" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:445
[!] Port "445" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:1617
[!] Port "1617" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:1617
[!] Port "1617" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:3306
[!] Port "3306" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:3306
[!] Port "3306" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:3389
[!] Port "3389" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:3389
[!] Port "3389" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:3700
[!] Port "3700" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:3700
[!] Port "3700" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:3820
[!] Port "3820" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:3820
[!] Port "3820" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:4848
[!] Port "4848" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:4848
[!] Port "4848" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:5985
[*] Port "5985" is web port. status=404
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:7676
[!] Port "7676" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:7676
[!] Port "7676" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8009
[!] Port "8009" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8009
[!] Port "8009" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8019
[!] Port "8019" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8019
[!] Port "8019" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8020
[*] Port "8020" is web port. status=200
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8022
[*] Port "8022" is web port. status=200
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8027
[!] Port "8027" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8027
[!] Port "8027" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8028
[!] Port "8028" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8028
[!] Port "8028" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8031
[!] Port "8031" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8031
[!] Port "8031" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8032
[!] Port "8032" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8032
[!] Port "8032" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8080
[*] Port "8080" is web port. status=200
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8181
[!] Port "8181" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8181
[!] Port "8181" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8282
[*] Port "8282" is web port. status=200
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8383
[*] Port "8383" is web port. status=400
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8443
[!] Port "8443" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8443
[!] Port "8443" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8444
[!] Port "8444" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8444
[!] Port "8444" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8484
[*] Port "8484" is web port. status=200
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8585
[*] Port "8585" is web port. status=200
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:8686
[!] Port "8686" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:8686
[!] Port "8686" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:9200
[*] Port "9200" is web port. status=200
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:9300
[!] Port "9300" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:9300
[!] Port "9300" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:31337
[!] Port "31337" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:31337
[!] Port "31337" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:47001
[*] Port "47001" is web port. status=404
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49152
[!] Port "49152" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49152
[!] Port "49152" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49153
[!] Port "49153" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49153
[!] Port "49153" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49154
[!] Port "49154" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49154
[!] Port "49154" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49155
[!] Port "49155" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49155
[!] Port "49155" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49156
[!] Port "49156" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49156
[!] Port "49156" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49169
[!] Port "49169" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49169
[!] Port "49169" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49170
[!] Port "49170" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49170
[!] Port "49170" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49227
[!] Port "49227" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49227
[!] Port "49227" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49228
[!] Port "49228" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49228
[!] Port "49228" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49237
[!] Port "49237" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49237
[!] Port "49237" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:49239
[!] Port "49239" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:49239
[!] Port "49239" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:58345
[!] Port "58345" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:58345
[!] Port "58345" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:58348
[!] Port "58348" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:58348
[!] Port "58348" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:58349
[!] Port "58349" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:58349
[!] Port "58349" is not web port.
[*] Executing keep_alive..
[*] Target URL: http://172.16.1.2:58350
[!] Port "58350" is not web port.
[*] Executing keep_alive..
[*] Target URL: https://172.16.1.2:58350
[!] Port "58350" is not web port.
2021-03-30 16:02:30 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:02:30 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:02:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:02:31 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:02:31 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:02:31 [scrapy.extensions.telnet] INFO: Telnet Password: c139eb2ad4189e71
2021-03-30 16:02:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_80.log
2021-03-30 16:02:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:02:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:02:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:02:31 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:02:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:02:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:02:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:80/> (referer: None)
2021-03-30 16:02:33 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:02:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 210,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 1117143,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 2.204895,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 2, 33, 997923),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'memusage/max': 315568128,
 'memusage/startup': 315568128,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 3, 30, 14, 2, 31, 793028)}
2021-03-30 16:02:33 [scrapy.core.engine] INFO: Spider closed (finished)
[!] [crawl_result/20210330160229_crawl_result.json] is empty.
2021-03-30 16:02:34 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:02:34 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:02:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:02:35 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:02:35 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:02:36 [scrapy.extensions.telnet] INFO: Telnet Password: 68377604c16913d7
2021-03-30 16:02:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_5985.log
2021-03-30 16:02:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:02:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:02:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:02:36 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:02:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:02:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:02:36 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://172.16.1.2:5985/> (referer: None)
2021-03-30 16:02:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://172.16.1.2:5985/>: HTTP status code is not handled or not allowed
2021-03-30 16:02:36 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:02:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 210,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 452,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 0.906949,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 2, 36, 950253),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 11,
 'memusage/max': 317304832,
 'memusage/startup': 317304832,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 3, 30, 14, 2, 36, 43304)}
2021-03-30 16:02:36 [scrapy.core.engine] INFO: Spider closed (finished)
[!] [crawl_result/20210330160234_crawl_result.json] is empty.
2021-03-30 16:02:37 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:02:37 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:02:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:02:38 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:02:38 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:02:38 [scrapy.extensions.telnet] INFO: Telnet Password: ca7bf61a98d6cf2a
2021-03-30 16:02:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_8020.log
2021-03-30 16:02:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:02:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:02:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:02:38 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:02:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:02:38 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:02:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (meta refresh) to <GET http://172.16.1.2:8020/configurations.do> from <GET http://172.16.1.2:8020/>
2021-03-30 16:02:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8020/configurations.do> (referer: None)
2021-03-30 16:02:43 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'forums.manageengine.com': <GET https://forums.manageengine.com/desktop-central>
2021-03-30 16:02:46 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'blogs.manageengine.com': <GET http://blogs.manageengine.com/desktopcentral>
2021-03-30 16:02:49 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'twitter.com': <GET https://twitter.com/me_itsm>
2021-03-30 16:02:52 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.facebook.com': <GET https://www.facebook.com/ManageEngine>
2021-03-30 16:02:55 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.manageengine.com': <GET http://www.manageengine.com/products/desktop-central/demo/desktop-management-videos.html?dci>
2021-03-30 16:03:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://172.16.1.2:8020/configurations.do> (referer: None)
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/Spider.py", line 55, in parse
    yield scrapy.Request(full_url, callback=self.parse_item)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/http/request/__init__.py", line 25, in __init__
    self._set_url(url)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/http/request/__init__.py", line 73, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: mailto:desktopcentral-support@manageengine.com
2021-03-30 16:03:22 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:03:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 437,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29695,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 43.653462,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 3, 22, 646101),
 'log_count/DEBUG': 7,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 316297216,
 'memusage/startup': 316297216,
 'offsite/domains': 5,
 'offsite/filtered': 13,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2021, 3, 30, 14, 2, 38, 992639)}
2021-03-30 16:03:22 [scrapy.core.engine] INFO: Spider closed (finished)
[!] [crawl_result/20210330160237_crawl_result.json] is empty.
2021-03-30 16:03:23 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:03:23 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:03:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:03:24 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:03:24 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:03:24 [scrapy.extensions.telnet] INFO: Telnet Password: a5112d0f51ebf38e
2021-03-30 16:03:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_8022.log
2021-03-30 16:03:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:03:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:03:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:03:24 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:03:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:03:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:03:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (meta refresh) to <GET http://172.16.1.2:8022/configurations.do> from <GET http://172.16.1.2:8022/>
2021-03-30 16:03:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8022/configurations.do> (referer: None)
2021-03-30 16:03:28 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'forums.manageengine.com': <GET https://forums.manageengine.com/desktop-central>
2021-03-30 16:03:31 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'blogs.manageengine.com': <GET http://blogs.manageengine.com/desktopcentral>
2021-03-30 16:03:34 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'twitter.com': <GET https://twitter.com/me_itsm>
2021-03-30 16:03:37 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.facebook.com': <GET https://www.facebook.com/ManageEngine>
2021-03-30 16:03:40 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.manageengine.com': <GET http://www.manageengine.com/products/desktop-central/demo/desktop-management-videos.html?dci>
2021-03-30 16:04:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://172.16.1.2:8022/configurations.do> (referer: None)
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/utils/defer.py", line 120, in iter_errback
    yield next(it)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/utils/python.py", line 353, in __next__
    return next(self.data)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/spidermiddlewares/referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/Spider.py", line 55, in parse
    yield scrapy.Request(full_url, callback=self.parse_item)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/http/request/__init__.py", line 25, in __init__
    self._set_url(url)
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/http/request/__init__.py", line 73, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: mailto:desktopcentral-support@manageengine.com
2021-03-30 16:04:07 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:04:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 437,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 29681,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 43.311232,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 4, 7, 978430),
 'log_count/DEBUG': 7,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 317247488,
 'memusage/startup': 317247488,
 'offsite/domains': 5,
 'offsite/filtered': 13,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2021, 3, 30, 14, 3, 24, 667198)}
2021-03-30 16:04:07 [scrapy.core.engine] INFO: Spider closed (finished)
[!] [crawl_result/20210330160323_crawl_result.json] is empty.
2021-03-30 16:04:08 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:04:08 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:04:08 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:04:09 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:04:10 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:04:10 [scrapy.extensions.telnet] INFO: Telnet Password: 6ca39c8b3be17fa7
2021-03-30 16:04:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_8080.log
2021-03-30 16:04:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:04:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:04:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:04:10 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:04:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:04:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:04:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8080/> (referer: None)
2021-03-30 16:04:13 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.oracle.com': <GET http://www.oracle.com>
2021-03-30 16:04:16 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'localhost': <GET http://localhost:4848>
2021-03-30 16:04:19 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'wikis.oracle.com': <GET http://wikis.oracle.com/display/IpsBestPractices/>
2021-03-30 16:04:22 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'metro.java.net': <GET http://metro.java.net/>
2021-03-30 16:04:25 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'jersey.java.net': <GET http://jersey.java.net/>
2021-03-30 16:04:32 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'glassfish.java.net': <GET http://glassfish.java.net>
2021-03-30 16:04:41 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://172.16.1.2:8080/copyright.html> (referer: http://172.16.1.2:8080/)
2021-03-30 16:04:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://172.16.1.2:8080/copyright.html>: HTTP status code is not handled or not allowed
2021-03-30 16:04:41 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:04:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 468,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 5880,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 31.127032,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 4, 41, 189176),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 8,
 'log_count/INFO': 11,
 'memusage/max': 322195456,
 'memusage/startup': 322195456,
 'offsite/domains': 6,
 'offsite/filtered': 9,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2021, 3, 30, 14, 4, 10, 62144)}
2021-03-30 16:04:41 [scrapy.core.engine] INFO: Spider closed (finished)
[!] [crawl_result/20210330160408_crawl_result.json] is empty.
2021-03-30 16:04:41 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:04:41 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:04:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:04:42 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:04:43 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:04:43 [scrapy.extensions.telnet] INFO: Telnet Password: 97f71146115ee336
2021-03-30 16:04:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_8282.log
2021-03-30 16:04:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:04:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:04:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:04:43 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:04:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:04:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:04:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/> (referer: None)
2021-03-30 16:04:47 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'tomcat.apache.org': <GET http://tomcat.apache.org/>
2021-03-30 16:04:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/> (referer: http://172.16.1.2:8282/)
2021-03-30 16:04:59 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'wiki.apache.org': <GET http://wiki.apache.org/tomcat/FrontPage>
2021-03-30 16:05:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/examples/> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:05:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://wiki.apache.org/tomcat/Specifications', 'http://www.jcp.org', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://tomcat.apache.org/connectors-doc/index.html', 'http://jcp.org/aboutJava/communityprocess/final/jsr340/index.html', 'http://docs.oracle.com/javaee/7/api/javax/servlet/package-summary.html', 'http://jcp.org/aboutJava/communityprocess/mrel/jsr245/index2.html', 'http://docs.oracle.com/javaee/7/api/javax/servlet/jsp/package-summary.html', 'http://jcp.org/aboutJava/communityprocess/final/jsr341/index.html', 'http://docs.oracle.com/javaee/7/api/javax/el/package-summary.html', 'https://jcp.org/aboutJava/communityprocess/mrel/jsr356/index.html', 'http://docs.oracle.com/javaee/7/api/javax/websocket/package-summary.html', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
2021-03-30 16:05:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/config/> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:05:18 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/examples/>
{'urls': ['http://172.16.1.2:8282/examples/servlets', 'http://172.16.1.2:8282/examples/jsp', 'http://172.16.1.2:8282/examples/websocket/index.xhtml']}
2021-03-30 16:05:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/security-howto.html> (referer: http://172.16.1.2:8282/)
2021-03-30 16:05:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/cluster-howto.html> (referer: http://172.16.1.2:8282/)
2021-03-30 16:05:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/manager-howto.html> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:05:22 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/config/>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://172.16.1.2:8282/docs/config/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/config/#comments_section', 'http://172.16.1.2:8282/docs/config/server.html', 'http://172.16.1.2:8282/docs/config/service.html', 'http://172.16.1.2:8282/docs/config/executor.html', 'http://172.16.1.2:8282/docs/config/http.html', 'http://172.16.1.2:8282/docs/config/ajp.html', 'http://172.16.1.2:8282/docs/config/context.html', 'http://172.16.1.2:8282/docs/config/engine.html', 'http://172.16.1.2:8282/docs/config/host.html', 'http://172.16.1.2:8282/docs/config/cluster.html', 'http://172.16.1.2:8282/docs/config/cookie-processor.html', 'http://172.16.1.2:8282/docs/config/credentialhandler.html', 'http://172.16.1.2:8282/docs/config/globalresources.html', 'http://172.16.1.2:8282/docs/config/jar-scanner.html', 'http://172.16.1.2:8282/docs/config/jar-scan-filter.html', 'http://172.16.1.2:8282/docs/config/listeners.html', 'http://172.16.1.2:8282/docs/config/loader.html', 'http://172.16.1.2:8282/docs/config/manager.html', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://172.16.1.2:8282/docs/config/resources.html', 'http://172.16.1.2:8282/docs/config/sessionidgenerator.html', 'http://172.16.1.2:8282/docs/config/valve.html', 'http://172.16.1.2:8282/docs/config/cluster.html', 'http://172.16.1.2:8282/docs/config/cluster-manager.html', 'http://172.16.1.2:8282/docs/config/cluster-channel.html', 'http://172.16.1.2:8282/docs/config/cluster-membership.html', 'http://172.16.1.2:8282/docs/config/cluster-sender.html', 'http://172.16.1.2:8282/docs/config/cluster-receiver.html', 'http://172.16.1.2:8282/docs/config/cluster-interceptor.html', 'http://172.16.1.2:8282/docs/config/cluster-valve.html', 'http://172.16.1.2:8282/docs/config/cluster-deployer.html', 'http://172.16.1.2:8282/docs/config/cluster-listener.html', 'http://172.16.1.2:8282/docs/config/filter.html', 'http://172.16.1.2:8282/docs/config/systemprops.html', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
2021-03-30 16:05:28 [scrapy.core.engine] DEBUG: Crawled (401) <GET http://172.16.1.2:8282/manager/html> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:05:28 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/security-howto.html>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/security-howto.html#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://172.16.1.2:8282/docs/security-howto.html#Introduction', 'http://172.16.1.2:8282/docs/security-howto.html#Non-Tomcat_settings', 'http://172.16.1.2:8282/docs/security-howto.html#Default_web_applications', 'http://172.16.1.2:8282/docs/security-howto.html#Default_web_applications/General', 'http://172.16.1.2:8282/docs/security-howto.html#ROOT', 'http://172.16.1.2:8282/docs/security-howto.html#Documentation', 'http://172.16.1.2:8282/docs/security-howto.html#Examples', 'http://172.16.1.2:8282/docs/security-howto.html#Default_web_applications/Manager', 'http://172.16.1.2:8282/docs/security-howto.html#Host_Manager', 'http://172.16.1.2:8282/docs/security-howto.html#Securing_Management_Applications', 'http://172.16.1.2:8282/docs/security-howto.html#Security_manager', 'http://172.16.1.2:8282/docs/security-howto.html#server.xml', 'http://172.16.1.2:8282/docs/security-howto.html#server.xml/General', 'http://172.16.1.2:8282/docs/security-howto.html#Server', 'http://172.16.1.2:8282/docs/security-howto.html#Listeners', 'http://172.16.1.2:8282/docs/security-howto.html#Connectors', 'http://172.16.1.2:8282/docs/security-howto.html#Host', 'http://172.16.1.2:8282/docs/security-howto.html#Context', 'http://172.16.1.2:8282/docs/security-howto.html#Valves', 'http://172.16.1.2:8282/docs/security-howto.html#Realms', 'http://172.16.1.2:8282/docs/security-howto.html#server.xml/Manager', 'http://172.16.1.2:8282/docs/security-howto.html#System_Properties', 'http://172.16.1.2:8282/docs/security-howto.html#web.xml', 'http://172.16.1.2:8282/docs/security-howto.html#General', 'http://172.16.1.2:8282/docs/config/realm.html#LockOut_Realm_-_org.apache.catalina.realm.LockOutRealm', 'http://172.16.1.2:8282/docs/config/valve.html#Remote_Address_Filter', 'http://172.16.1.2:8282/docs/config/filter.html', 'https://www.openssl.org/docs/apps/ciphers.html', 'https://www.ssllabs.com/ssltest/index.html', 'http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2009-3555', 'http://tomcat.apache.org/security-8.html', 'http://172.16.1.2:8282/docs/config/context.html', 'http://172.16.1.2:8282/docs/config/resources.html', 'http://172.16.1.2:8282/docs/config/valve.html', 'http://172.16.1.2:8282/docs/config/valve.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/config/filter.html', 'http://172.16.1.2:8282/docs/config/filter.html', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
[*] Executing keep_alive..
2021-03-30 16:05:29 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/cluster-howto.html>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/cluster-howto.html#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://172.16.1.2:8282/docs/config/cluster.html', 'http://172.16.1.2:8282/docs/cluster-howto.html#For_the_impatient', 'http://172.16.1.2:8282/docs/cluster-howto.html#Cluster_Basics', 'http://172.16.1.2:8282/docs/cluster-howto.html#Overview', 'http://172.16.1.2:8282/docs/cluster-howto.html#Cluster_Information', 'http://172.16.1.2:8282/docs/cluster-howto.html#Bind_session_after_crash_to_failover_node', 'http://172.16.1.2:8282/docs/cluster-howto.html#Configuration_Example', 'http://172.16.1.2:8282/docs/cluster-howto.html#Cluster_Architecture', 'http://172.16.1.2:8282/docs/cluster-howto.html#How_it_Works', 'http://172.16.1.2:8282/docs/cluster-howto.html#Monitoring_your_Cluster_with_JMX', 'http://172.16.1.2:8282/docs/cluster-howto.html#FAQ', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://tomcat.apache.org/tomcat-8.0-doc/api/org/apache/catalina/tribes/Channel.html', 'http://tomcat.apache.org/tomcat-8.0-doc/api/org/apache/catalina/tribes/Channel.html', 'http://172.16.1.2:8282/docs/config/cluster.html', 'http://172.16.1.2:8282/docs/config/cluster-manager.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://172.16.1.2:8282/docs/config/cluster-channel.html', 'http://172.16.1.2:8282/docs/config/cluster-membership.html', 'http://172.16.1.2:8282/docs/config/cluster-receiver.html', 'http://172.16.1.2:8282/docs/config/cluster-sender.html', 'http://172.16.1.2:8282/docs/config/cluster-interceptor.html', 'http://172.16.1.2:8282/docs/config/cluster-valve.html', 'http://172.16.1.2:8282/docs/config/cluster-deployer.html', 'http://172.16.1.2:8282/docs/config/cluster-listener.html', 'http://wiki.apache.org/tomcat/FAQ/Clustering', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
[*] Executing keep_alive..
2021-03-30 16:05:30 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/manager-howto.html>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/manager-howto.html#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://172.16.1.2:8282/docs/manager-howto.html#Introduction', 'http://172.16.1.2:8282/docs/manager-howto.html#Configuring_Manager_Application_Access', 'http://172.16.1.2:8282/docs/manager-howto.html#HTML_User-friendly_Interface', 'http://172.16.1.2:8282/docs/manager-howto.html#Supported_Manager_Commands', 'http://172.16.1.2:8282/docs/manager-howto.html#Common_Parameters', 'http://172.16.1.2:8282/docs/manager-howto.html#Deploy_A_New_Application_Archive_(WAR)_Remotely', 'http://172.16.1.2:8282/docs/manager-howto.html#Deploy_A_New_Application_from_a_Local_Path', 'http://172.16.1.2:8282/docs/manager-howto.html#Deploy_a_previously_deployed_webapp', 'http://172.16.1.2:8282/docs/manager-howto.html#Deploy_a_Directory_or_WAR_by_URL', 'http://172.16.1.2:8282/docs/manager-howto.html#Deploy_a_Directory_or_War_from_the_Host_appBase', 'http://172.16.1.2:8282/docs/manager-howto.html#Deploy_using_a_Context_configuration_%22.xml%22_file', 'http://172.16.1.2:8282/docs/manager-howto.html#Deployment_Notes', 'http://172.16.1.2:8282/docs/manager-howto.html#Deploy_Response', 'http://172.16.1.2:8282/docs/manager-howto.html#List_Currently_Deployed_Applications', 'http://172.16.1.2:8282/docs/manager-howto.html#Reload_An_Existing_Application', 'http://172.16.1.2:8282/docs/manager-howto.html#List_OS_and_JVM_Properties', 'http://172.16.1.2:8282/docs/manager-howto.html#List_Available_Global_JNDI_Resources', 'http://172.16.1.2:8282/docs/manager-howto.html#Session_Statistics', 'http://172.16.1.2:8282/docs/manager-howto.html#Expire_Sessions', 'http://172.16.1.2:8282/docs/manager-howto.html#Start_an_Existing_Application', 'http://172.16.1.2:8282/docs/manager-howto.html#Stop_an_Existing_Application', 'http://172.16.1.2:8282/docs/manager-howto.html#Undeploy_an_Existing_Application', 'http://172.16.1.2:8282/docs/manager-howto.html#Finding_memory_leaks', 'http://172.16.1.2:8282/docs/manager-howto.html#Connector_SSL/TLS_diagnostics', 'http://172.16.1.2:8282/docs/manager-howto.html#Thread_Dump', 'http://172.16.1.2:8282/docs/manager-howto.html#VM_Info', 'http://172.16.1.2:8282/docs/manager-howto.html#Save_Configuration', 'http://172.16.1.2:8282/docs/manager-howto.html#Server_Status', 'http://172.16.1.2:8282/docs/manager-howto.html#Using_the_JMX_Proxy_Servlet', 'http://172.16.1.2:8282/docs/manager-howto.html#What_is_JMX_Proxy_Servlet', 'http://172.16.1.2:8282/docs/manager-howto.html#JMX_Query_command', 'http://172.16.1.2:8282/docs/manager-howto.html#JMX_Get_command', 'http://172.16.1.2:8282/docs/manager-howto.html#JMX_Set_command', 'http://172.16.1.2:8282/docs/manager-howto.html#JMX_Invoke_command', 'http://172.16.1.2:8282/docs/manager-howto.html#Executing_Manager_Commands_With_Ant', 'http://172.16.1.2:8282/docs/manager-howto.html#Tasks_output_capture', 'http://172.16.1.2:8282/docs/manager-howto.html#Supported_Manager_Commands', 'http://172.16.1.2:8282/docs/manager-howto.html#Executing_Manager_Commands_With_Ant', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://172.16.1.2:8282/docs/config/valve.html#Remote_Address_Filter', 'http://172.16.1.2:8282/docs/html-manager-howto.html', 'http://172.16.1.2:8282/docs/config/context.html', 'http://172.16.1.2:8282/docs/config/listeners.html#StoreConfig_Lifecycle_Listener_-_org.apache.catalina.storeconfig.StoreConfigLifecycleListener', 'http://ant.apache.org', 'http://ant.apache.org', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
2021-03-30 16:05:33 [scrapy.core.engine] DEBUG: Crawled (401) <GET http://172.16.1.2:8282/manager/status> (referer: http://172.16.1.2:8282/)
2021-03-30 16:05:33 [scrapy.core.engine] DEBUG: Crawled (401) <GET http://172.16.1.2:8282/host-manager/html> (referer: http://172.16.1.2:8282/)
2021-03-30 16:05:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <401 http://172.16.1.2:8282/manager/html>: HTTP status code is not handled or not allowed
2021-03-30 16:05:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/setup.html> (referer: http://172.16.1.2:8282/)
2021-03-30 16:05:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <401 http://172.16.1.2:8282/manager/status>: HTTP status code is not handled or not allowed
2021-03-30 16:05:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <401 http://172.16.1.2:8282/host-manager/html>: HTTP status code is not handled or not allowed
2021-03-30 16:05:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/appdev/> (referer: http://172.16.1.2:8282/)
2021-03-30 16:05:42 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://172.16.1.2:8282/examples/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2021-03-30 16:05:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/realm-howto.html> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:05:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/setup.html>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/setup.html#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://172.16.1.2:8282/docs/setup.html#Introduction', 'http://172.16.1.2:8282/docs/setup.html#Windows', 'http://172.16.1.2:8282/docs/setup.html#Unix_daemon', 'http://172.16.1.2:8282/docs/RUNNING.txt', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
2021-03-30 16:05:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:05:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/appdev/>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/appdev/#comments_section', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/appdev/introduction.html', 'http://172.16.1.2:8282/docs/appdev/installation.html', 'http://172.16.1.2:8282/docs/appdev/deployment.html', 'http://172.16.1.2:8282/docs/appdev/source.html', 'http://172.16.1.2:8282/docs/appdev/processes.html', 'http://172.16.1.2:8282/docs/appdev/sample/', 'mailto:craigmcc@apache.org', 'http://172.16.1.2:8282/docs/appdev/introduction.html', 'http://172.16.1.2:8282/docs/appdev/installation.html', 'http://172.16.1.2:8282/docs/appdev/deployment.html', 'http://172.16.1.2:8282/docs/appdev/source.html', 'http://172.16.1.2:8282/docs/appdev/processes.html', 'http://172.16.1.2:8282/docs/appdev/sample/', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
2021-03-30 16:05:52 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 14 pages/min), scraped 8 items (at 8 items/min)
[*] Executing keep_alive..
2021-03-30 16:05:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/realm-howto.html>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/realm-howto.html#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://172.16.1.2:8282/docs/realm-howto.html#Quick_Start', 'http://172.16.1.2:8282/docs/realm-howto.html#Overview', 'http://172.16.1.2:8282/docs/realm-howto.html#What_is_a_Realm?', 'http://172.16.1.2:8282/docs/realm-howto.html#Configuring_a_Realm', 'http://172.16.1.2:8282/docs/realm-howto.html#Common_Features', 'http://172.16.1.2:8282/docs/realm-howto.html#Digested_Passwords', 'http://172.16.1.2:8282/docs/realm-howto.html#Example_Application', 'http://172.16.1.2:8282/docs/realm-howto.html#Manager_Application', 'http://172.16.1.2:8282/docs/realm-howto.html#Realm_Logging', 'http://172.16.1.2:8282/docs/realm-howto.html#Standard_Realm_Implementations', 'http://172.16.1.2:8282/docs/realm-howto.html#JDBCRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#DataSourceRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#JNDIRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#UserDatabaseRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#MemoryRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#JAASRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#CombinedRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#LockOutRealm', 'http://wiki.apache.org/tomcat/Specifications', 'http://172.16.1.2:8282/docs/config/host.html#Single_Sign_On', 'http://172.16.1.2:8282/docs/realm-howto.html#JDBCRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#DataSourceRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#JNDIRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#UserDatabaseRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#MemoryRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#JAASRealm', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://localhost:8080/examples/jsp/security/protected/', 'http://172.16.1.2:8282/docs/realm-howto.html#UserDatabaseRealm', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/config/context.html', 'http://172.16.1.2:8282/docs/config/host.html', 'http://172.16.1.2:8282/docs/config/engine.html', 'http://172.16.1.2:8282/docs/realm-howto.html#Configuring_a_Realm', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html#Configuring_a_Realm', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://172.16.1.2:8282/docs/realm-howto.html#Digested_Passwords', 'http://172.16.1.2:8282/docs/realm-howto.html#Configuring_a_Realm', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://www.openldap.org', 'http://docs.oracle.com/javase/7/docs/technotes/guides/jndi/index.html', 'http://172.16.1.2:8282/docs/realm-howto.html#Configuring_a_Realm', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://172.16.1.2:8282/docs/realm-howto.html#MemoryRealm', 'http://172.16.1.2:8282/docs/realm-howto.html#Configuring_a_Realm', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://172.16.1.2:8282/docs/realm-howto.html#Digested_Passwords', 'http://www.jcp.org/en/jsr/detail?id=196', 'http://docs.oracle.com/javase/7/docs/technotes/guides/security/jaas/tutorials/GeneralAcnOnly.html', 'http://docs.oracle.com/javase/7/docs/technotes/guides/security/jaas/JAASLMDevGuide.html', 'http://docs.oracle.com/javase/7/docs/technotes/guides/security/jaas/tutorials/LoginConfigFile.html', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://172.16.1.2:8282/docs/config/realm.html', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
[*] Executing keep_alive..
2021-03-30 16:05:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Introduction', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#DriverManager,_the_service_provider_mechanism_and_memory_leaks', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Database_Connection_Pool_(DBCP_2)_Configurations', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Installation', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Preventing_database_connection_pool_leaks', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#MySQL_DBCP_Example', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Oracle_8i,_9i_&_10g', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#PostgreSQL', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Non-DBCP_Solutions', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Oracle_8i_with_OCI_client', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Oracle_8i_with_OCI_client/Introduction', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Putting_it_all_together', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Common_Problems', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Intermittent_Database_Connection_Failures', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Random_Connection_Closed_Exceptions', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#Context_versus_GlobalNamingResources', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html#JNDI_Resource_Naming_and_Realm_Interaction', 'http://tomcat.apache.org/migration.html', 'http://172.16.1.2:8282/docs/config/context.html', 'http://172.16.1.2:8282/docs/config/host.html', 'http://docs.oracle.com/javase/6/docs/api/index.html?java/sql/DriverManager.html', 'http://172.16.1.2:8282/docs/config/listeners.html', 'http://commons.apache.org/', 'http://commons.apache.org/dbcp/configuration.html', 'http://commons.apache.org/dbcp/configuration.html', 'http://www.mysql.com/products/mysql/index.html', 'http://www.mysql.com/products/connector-j', 'http://mmmysql.sourceforge.net', 'http://172.16.1.2:8282/docs/config/context.html', 'http://www.oracle.com/technetwork/java/index-jsp-135995.html', 'http://tomcat.apache.org/taglibs/standard/', 'http://172.16.1.2:8282/docs/config/context.html', 'http://172.16.1.2:8282/docs/config/context.html', 'http://otn.oracle.com/', 'http://172.16.1.2:8282/docs/config/globalresources.html', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
2021-03-30 16:06:26 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'svn.apache.org': <GET http://svn.apache.org/repos/asf/tomcat/tc8.0.x/>
2021-03-30 16:06:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/RELEASE-NOTES.txt> (referer: http://172.16.1.2:8282/)
2021-03-30 16:06:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8282/docs/changelog.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:06:59 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 1 pages/min), scraped 10 items (at 2 items/min)
2021-03-30 16:07:32 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.apache.org': <GET http://www.apache.org/foundation/sponsorship.html>
2021-03-30 16:07:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8282/docs/api/index.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
[*] Executing keep_alive..
2021-03-30 16:07:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/RELEASE-NOTES.txt>
{'urls': []}
2021-03-30 16:07:48 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 0 pages/min), scraped 11 items (at 1 items/min)
2021-03-30 16:07:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8282/docs/changelog.html> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:07:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/api/index.html> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:07:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/api/index.html>
{'urls': ['http://tomcat.apache.org/tomcat-8.0-doc/']}
2021-03-30 16:07:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/deployer-howto.html> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:07:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/deployer-howto.html>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/deployer-howto.html#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://172.16.1.2:8282/docs/deployer-howto.html#Introduction', 'http://172.16.1.2:8282/docs/deployer-howto.html#Installation', 'http://172.16.1.2:8282/docs/deployer-howto.html#A_word_on_Contexts', 'http://172.16.1.2:8282/docs/deployer-howto.html#Deployment_on_Tomcat_startup', 'http://172.16.1.2:8282/docs/deployer-howto.html#Deploying_on_a_running_Tomcat_server', 'http://172.16.1.2:8282/docs/deployer-howto.html#Deploying_using_the_Tomcat_Manager', 'http://172.16.1.2:8282/docs/deployer-howto.html#Deploying_using_the_Client_Deployer_Package', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://tomcat.apache.org/maven-plugin.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/deployer-howto.html#Deploying_using_the_Client_Deployer_Package', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://tomcat.apache.org/findhelp.html', 'http://tomcat.apache.org/lists.html', 'http://172.16.1.2:8282/docs/comments.html']}
2021-03-30 16:07:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8282/docs/changelog.html> (referer: http://172.16.1.2:8282/)
[*] Executing keep_alive..
2021-03-30 16:07:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8282/docs/changelog.html>
{'urls': ['http://tomcat.apache.org/', 'http://www.apache.org/', 'http://172.16.1.2:8282/docs/index.html', 'http://wiki.apache.org/tomcat/FAQ', 'http://172.16.1.2:8282/docs/changelog.html#comments_section', 'http://172.16.1.2:8282/docs/introduction.html', 'http://172.16.1.2:8282/docs/setup.html', 'http://172.16.1.2:8282/docs/appdev/index.html', 'http://172.16.1.2:8282/docs/deployer-howto.html', 'http://172.16.1.2:8282/docs/manager-howto.html', 'http://172.16.1.2:8282/docs/realm-howto.html', 'http://172.16.1.2:8282/docs/security-manager-howto.html', 'http://172.16.1.2:8282/docs/jndi-resources-howto.html', 'http://172.16.1.2:8282/docs/jndi-datasource-examples-howto.html', 'http://172.16.1.2:8282/docs/class-loader-howto.html', 'http://172.16.1.2:8282/docs/jasper-howto.html', 'http://172.16.1.2:8282/docs/ssl-howto.html', 'http://172.16.1.2:8282/docs/ssi-howto.html', 'http://172.16.1.2:8282/docs/cgi-howto.html', 'http://172.16.1.2:8282/docs/proxy-howto.html', 'http://172.16.1.2:8282/docs/mbeans-descriptor-howto.html', 'http://172.16.1.2:8282/docs/default-servlet.html', 'http://172.16.1.2:8282/docs/cluster-howto.html', 'http://172.16.1.2:8282/docs/balancer-howto.html', 'http://172.16.1.2:8282/docs/connectors.html', 'http://172.16.1.2:8282/docs/monitoring.html', 'http://172.16.1.2:8282/docs/logging.html', 'http://172.16.1.2:8282/docs/apr.html', 'http://172.16.1.2:8282/docs/virtual-hosting-howto.html', 'http://172.16.1.2:8282/docs/aio.html', 'http://172.16.1.2:8282/docs/extras.html', 'http://172.16.1.2:8282/docs/maven-jars.html', 'http://172.16.1.2:8282/docs/security-howto.html', 'http://172.16.1.2:8282/docs/windows-service-howto.html', 'http://172.16.1.2:8282/docs/windows-auth-howto.html', 'http://172.16.1.2:8282/docs/jdbc-pool.html', 'http://172.16.1.2:8282/docs/web-socket-howto.html', 'http://172.16.1.2:8282/docs/rewrite.html', 'http://172.16.1.2:8282/docs/RELEASE-NOTES.txt', 'http://172.16.1.2:8282/docs/config/index.html', 'http://172.16.1.2:8282/docs/api/index.html', 'http://172.16.1.2:8282/docs/servletapi/index.html', 'http://172.16.1.2:8282/docs/jspapi/index.html', 'http://172.16.1.2:8282/docs/elapi/index.html', 'http://172.16.1.2:8282/docs/websocketapi/index.html', 'http://tomcat.apache.org/connectors-doc/', 'http://172.16.1.2:8282/docs/building.html', 'http://172.16.1.2:8282/docs/changelog.html', 'http://wiki.apache.org/tomcat/TomcatVersions', 'http://172.16.1.2:8282/docs/developers.html', 'http://172.16.1.2:8282/docs/architecture/index.html', 'http://172.16.1.2:8282/docs/funcspecs/index.html', 'http://172.16.1.2:8282/docs/tribes/introduction.html', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58867', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58351', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58988', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58999', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57809', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59001', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59001', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59043', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59054', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59065', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59115', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59123', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59138', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59145', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59151', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56917', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59154', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58646', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59015', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59081', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59089', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57583', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58111', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59014', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59119', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59134', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59189', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58935', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58283', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=59031', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58768', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58946', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58827', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58905', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57215', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58692', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58701', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58702', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58735', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58751', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58765', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58766', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58809', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58836', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58867', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58900', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57489', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58723', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=34319', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56917', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58629', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58635', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58660', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58655', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56917', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58657', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57136#c25', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55006', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58624', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58631', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58596', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57136', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57799', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58228', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58486', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58490', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58497', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58508', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58518', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56777', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56777', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58519', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58534', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58535', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58537', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58546', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58540', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58541', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58544', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58541', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58547', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58545', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58578', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58581', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58582', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58603', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58489', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56777', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58474', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58187', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57765', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58284', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58313', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58320', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58352', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58368', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58369', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58372', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58373', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58374', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58380', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58385', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58394', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58398', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58412', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58416', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58436', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58845', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58275', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58357', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58367', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58370', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58371', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58375', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58377', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58379', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58387', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58388', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58389', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58390', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58396', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57799', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57136', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58296', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58327', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58340', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58424', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58427', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58444', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58342', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58414', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58381', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58382', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58383', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58386', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58391', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58392', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58393', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58395', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58397', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58344', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58255', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57741', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58031', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58086', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58096', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58116', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57281', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58125', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58179', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58192', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58023', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58228', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58230', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57943', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58103', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58151', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58157', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58110', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58119', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58178', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58178', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58166', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58232', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58112', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58042', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57938', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57977', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58015', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58023', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57700', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58086', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57265', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57936', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57943', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57944', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58004', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57969', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57974', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57282', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57971', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57758', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57783', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=58042', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54618', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57875', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57871', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57926', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57931', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56438', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57802', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57887', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57875', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57896', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57736', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57752', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57556', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57765', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57772', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57801', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57841', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57856', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57863', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57779', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57833', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57837', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57845', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57855', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57761', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57762', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57776', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57788', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57759', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57864', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57707', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=49785', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55988', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56608', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57601', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57602', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57621', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57637', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57645', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57190', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57675', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57704', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57724', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57743', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57540', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57570', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57592', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57638', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57674', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57708', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57135', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57583', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57626', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57627', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57647', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57662', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57676', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56058', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57587', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57644', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57683', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57377', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57703', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57180', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57472', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57534', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57556', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57021', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57432', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57509', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57544', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57546', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57581', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57123', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57564', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57574', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57490', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57503', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57496', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57558', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57178', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57425', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57431', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57446', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57455', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57461', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57476', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57252', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57481', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57441', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57473', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57252', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57172', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57173', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56953', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57180', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57190', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57208', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57209', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57215', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57216', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57239', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57252', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57281', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57308', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57326', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57331', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57363', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57187', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57234', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57265', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57324', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57340', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57347', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57391', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57142', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57247', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57309', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57338', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57238', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57245', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57261', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57267', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57323', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57285', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57344', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=43548', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=43682', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=47919', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=49939', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55951', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55984', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56393', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56394', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56401', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56403', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57016', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57022', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57027', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57038', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57089', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57105', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57153', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57155', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=53952', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57157', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57099', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57113', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57132', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57136', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57148', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57153', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57141', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57054', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57091', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57118', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57049', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57147', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=45282', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57005', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57079', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56079', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56596', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56079', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55917', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55918', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55921', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56401', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56530', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56900', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56902', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56903', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56825', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56938', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57004', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57011', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56910', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=43001', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56908', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56991', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56905', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56907', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56982', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56895', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56988', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56990', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56882', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56568', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56323', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56658', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56710', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56712', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56717', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56724', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56736', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56739', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56784', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56785', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56796', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56801', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56815', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56825', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56840', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56848', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56857', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56661', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56780', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56810', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56709', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56797', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56746', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=53088', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=53200', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=53853', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54225', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54227', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54235', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54395', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54537', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54978', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56318', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56789', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56788', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56829', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=44312', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56611', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56588', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56653', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56657', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56658', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56665', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56666', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56677', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56684', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56693', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56698', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56663', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56704', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56543', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56652', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56694', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56596', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56685', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55282', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55975', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56387', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56399', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56461', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56526', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56545', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56546', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56578', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56339', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56588', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56600', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56606', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56518', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56521', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56582', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56582#c1', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56620', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56334#c15', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56543', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56561', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56568', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56581', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56612', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56636', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56638', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56446', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56577', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56536', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56529', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56523', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56399', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56522', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56027', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56320', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56321', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56327', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56339', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56365', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56369', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56382', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56383', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56390', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56409', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56430', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56441', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56463', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56472', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56481', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56492', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56501', 'http://svn.apache.org/viewvc?view=rev&rev=1239520', 'http://svn.apache.org/viewvc?view=rev&rev=797162', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56336', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56348', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56416', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56518', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56334', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55735', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56425', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56343', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56449', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56458', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56418', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56513', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56363', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56190', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56293', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54475', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56273', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56304', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54315', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56125', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56190', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56236', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56244', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56246', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56248', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56253', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56172', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56179', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56177', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56199', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56223', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56265', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56283', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56093', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56217', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56115', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56143', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56137', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56139', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56189', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56204', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56082', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56085', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56096', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=56104', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55996', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=46727', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=45995', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=51408', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=52092', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=52558', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=52767', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54095', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54708', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55101', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55166', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55246', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55317', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55620', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=57896', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54010', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55246', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55251', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=48550', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55383', 'http://svn.apache.org/viewvc?view=rev&rev=1353242', 'http://svn.apache.org/viewvc?view=rev&rev=1353410', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=53529', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=54899', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55166', 'http://bz.apache.org/bugzilla/show_bug.cgi?id=55372']}
2021-03-30 16:07:50 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:07:50 [scrapy.extensions.feedexport] INFO: Stored json feed (14 items) in: crawl_result/20210330160441_crawl_result.json
2021-03-30 16:07:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'downloader/request_bytes': 5458,
 'downloader/request_count': 21,
 'downloader/request_method_count/GET': 21,
 'downloader/response_bytes': 684380,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 15,
 'downloader/response_status_count/401': 3,
 'dupefilter/filtered': 6,
 'elapsed_time_seconds': 187.494838,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 7, 50, 730039),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/401': 3,
 'item_scraped_count': 14,
 'log_count/DEBUG': 40,
 'log_count/INFO': 17,
 'memusage/max': 322527232,
 'memusage/startup': 317358080,
 'offsite/domains': 4,
 'offsite/filtered': 36,
 'request_depth_max': 1,
 'response_received_count': 18,
 'retry/count': 3,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 3,
 'scheduler/dequeued': 21,
 'scheduler/dequeued/memory': 21,
 'scheduler/enqueued': 21,
 'scheduler/enqueued/memory': 21,
 'start_time': datetime.datetime(2021, 3, 30, 14, 4, 43, 235201)}
2021-03-30 16:07:50 [scrapy.core.engine] INFO: Spider closed (finished)
2021-03-30 16:07:51 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:07:51 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:07:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:07:52 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:07:52 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:07:52 [scrapy.extensions.telnet] INFO: Telnet Password: 67c0346616da4bdd
2021-03-30 16:07:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_8383.log
2021-03-30 16:07:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:07:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:07:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:07:52 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:07:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:07:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:07:53 [scrapy.core.engine] DEBUG: Crawled (400) <GET http://172.16.1.2:8383/> (referer: None)
2021-03-30 16:07:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 http://172.16.1.2:8383/>: HTTP status code is not handled or not allowed
2021-03-30 16:07:53 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:07:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 210,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 488,
 'downloader/response_count': 1,
 'downloader/response_status_count/400': 1,
 'elapsed_time_seconds': 0.848246,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 7, 53, 712097),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/400': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 11,
 'memusage/max': 319754240,
 'memusage/startup': 319754240,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 3, 30, 14, 7, 52, 863851)}
2021-03-30 16:07:53 [scrapy.core.engine] INFO: Spider closed (finished)
[!] [crawl_result/20210330160751_crawl_result.json] is empty.
2021-03-30 16:07:54 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:07:54 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:07:54 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:07:55 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:07:55 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:07:55 [scrapy.extensions.telnet] INFO: Telnet Password: e351b0933e89ca2e
2021-03-30 16:07:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_8484.log
2021-03-30 16:07:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:07:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:07:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:07:55 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:07:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:07:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:07:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/> (referer: None)
2021-03-30 16:07:59 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://172.16.1.2:8484/#skip2content> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2021-03-30 16:08:05 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'wiki.jenkins-ci.org': <GET http://wiki.jenkins-ci.org/display/JENKINS/Search+Box>
2021-03-30 16:08:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/?auto_refresh=true> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/view/All/newJob> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:26 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/?auto_refresh=true> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/asynchPeople/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/view/All/newJob> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/view/All/builds> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/?auto_refresh=true> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:38 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/asynchPeople/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/?auto_refresh=true>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/manage> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:41 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/view/All/newJob> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/view/All/builds> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/view/All/newJob>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/credential-store> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/asynchPeople/> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/manage> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/asynchPeople/>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/toggleCollapse?paneId=buildQueue> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:53 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/view/All/builds> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/toggleCollapse?paneId=executors> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/credential-store> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:56 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/view/All/builds>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:56 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:08:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/computer/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:08:59 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/manage> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:02 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'jenkins-ci.org': <GET http://jenkins-ci.org/>
2021-03-30 16:09:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/editDescription> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/toggleCollapse?paneId=buildQueue> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:05 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/manage>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/newJob> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/toggleCollapse?paneId=executors> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/credential-store> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/api/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/computer/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:11 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/credential-store>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/editDescription> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:14 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/toggleCollapse?paneId=buildQueue> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/prototype.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/newJob> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:17 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/toggleCollapse?paneId=executors> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/toggleCollapse?paneId=buildQueue>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/behavior.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/api/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:21 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/computer/> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/toggleCollapse?paneId=executors>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/adjuncts/3e037639/org/kohsuke/stapler/bind.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:24 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/editDescription> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/computer/>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/yahoo/yahoo-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/prototype.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:27 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/newJob> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/editDescription>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/dom/dom-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/behavior.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/api/> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/newJob>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/event/event-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/adjuncts/3e037639/org/kohsuke/stapler/bind.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/api/>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/animation/animation-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/yahoo/yahoo-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:36 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/prototype.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/dragdrop/dragdrop-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/dom/dom-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:39 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/behavior.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:39 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/prototype.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/container/container-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/event/event-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:42 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/behavior.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/adjuncts/3e037639/org/kohsuke/stapler/bind.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/connection/connection-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/animation/animation-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:48 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/yahoo/yahoo-min.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/datasource/datasource-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/dragdrop/dragdrop-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/adjuncts/3e037639/org/kohsuke/stapler/bind.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:51 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/dom/dom-min.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/autocomplete/autocomplete-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:51 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/yahoo/yahoo-min.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/container/container-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:54 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/event/event-min.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/menu/menu-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/dom/dom-min.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/connection/connection-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:57 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/animation/animation-min.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/element/element-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/event/event-min.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:09:57 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:10:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/datasource/datasource-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/dragdrop/dragdrop-min.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/animation/animation-min.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/button/button-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/autocomplete/autocomplete-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/storage/storage-min.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/dragdrop/dragdrop-min.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/menu/menu-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:06 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/container/container-min.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/hudson-behavior.js> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/element/element-min.js> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:09 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/connection/connection-min.js> (failed 3 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/container/container-min.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/cookie/cookie-min.js> (referer: http://172.16.1.2:8484/)
2021-03-30 16:10:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/connection/connection-min.js>
Traceback (most recent call last):
  File "/home/ludovic/Test_Lab/machine_learning_security/DeepExploit/.venv/lib/python3.8/site-packages/scrapy/core/downloader/middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-03-30 16:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/storage/storage-min.js> (referer: http://172.16.1.2:8484/)
2021-03-30 16:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/sortable.js> (referer: http://172.16.1.2:8484/)
2021-03-30 16:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/adjuncts/3e037639/lib/layout/breadcrumbs.js> (referer: http://172.16.1.2:8484/)
2021-03-30 16:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/datasource/datasource-min.js> (referer: http://172.16.1.2:8484/)
2021-03-30 16:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/autocomplete/autocomplete-min.js> (referer: http://172.16.1.2:8484/)
2021-03-30 16:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/button/button-min.js> (referer: http://172.16.1.2:8484/)
[*] Executing keep_alive..
2021-03-30 16:10:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/yui/cookie/cookie-min.js>
{'urls': []}
2021-03-30 16:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/element/element-min.js> (referer: http://172.16.1.2:8484/)
2021-03-30 16:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/yui/menu/menu-min.js> (referer: http://172.16.1.2:8484/)
2021-03-30 16:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8484/static/3e037639/scripts/hudson-behavior.js> (referer: http://172.16.1.2:8484/)
[*] Executing keep_alive..
2021-03-30 16:10:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/yui/storage/storage-min.js>
{'urls': []}
[*] Executing keep_alive..
2021-03-30 16:10:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/sortable.js>
{'urls': ['http://172.16.1.2:8484/static/3e037639/scripts/sortable.js']}
[*] Executing keep_alive..
2021-03-30 16:10:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/adjuncts/3e037639/lib/layout/breadcrumbs.js>
{'urls': []}
[*] Executing keep_alive..
2021-03-30 16:10:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/yui/datasource/datasource-min.js>
{'urls': []}
[*] Executing keep_alive..
2021-03-30 16:10:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/yui/autocomplete/autocomplete-min.js>
{'urls': []}
[*] Executing keep_alive..
2021-03-30 16:10:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/yui/button/button-min.js>
{'urls': []}
[*] Executing keep_alive..
2021-03-30 16:10:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/yui/element/element-min.js>
{'urls': []}
[*] Executing keep_alive..
2021-03-30 16:10:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/yui/menu/menu-min.js>
{'urls': ['http://172.16.1.2:8484/static/3e037639/scripts/yui/menu/menu-min.js']}
[*] Executing keep_alive..
2021-03-30 16:10:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8484/static/3e037639/scripts/hudson-behavior.js>
{'urls': []}
2021-03-30 16:10:15 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:10:15 [scrapy.extensions.feedexport] INFO: Stored json feed (10 items) in: crawl_result/20210330160754_crawl_result.json
2021-03-30 16:10:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 77,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 77,
 'downloader/request_bytes': 29197,
 'downloader/request_count': 88,
 'downloader/request_method_count/GET': 88,
 'downloader/response_bytes': 89963,
 'downloader/response_count': 11,
 'downloader/response_status_count/200': 11,
 'dupefilter/filtered': 10,
 'elapsed_time_seconds': 139.895816,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 10, 15, 696405),
 'item_scraped_count': 10,
 'log_count/DEBUG': 79,
 'log_count/ERROR': 44,
 'log_count/INFO': 13,
 'memusage/max': 325451776,
 'memusage/startup': 323309568,
 'offsite/domains': 2,
 'offsite/filtered': 2,
 'request_depth_max': 1,
 'response_received_count': 11,
 'retry/count': 55,
 'retry/max_reached': 22,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 55,
 'scheduler/dequeued': 88,
 'scheduler/dequeued/memory': 88,
 'scheduler/enqueued': 88,
 'scheduler/enqueued/memory': 88,
 'start_time': datetime.datetime(2021, 3, 30, 14, 7, 55, 800589)}
2021-03-30 16:10:15 [scrapy.core.engine] INFO: Spider closed (finished)
2021-03-30 16:10:16 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:10:16 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:10:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:10:17 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:10:17 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:10:17 [scrapy.extensions.telnet] INFO: Telnet Password: 2586a26d9d81eaa4
2021-03-30 16:10:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_8585.log
2021-03-30 16:10:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:10:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:10:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:10:17 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:10:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:10:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:10:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8585/> (referer: None)
2021-03-30 16:10:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8585/?lang=fr> (referer: http://172.16.1.2:8585/)
2021-03-30 16:10:39 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://172.16.1.2:8585/phpmyadmin/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2021-03-30 16:10:39 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://172.16.1.2:8585/phpmyadmin/> (referer: http://172.16.1.2:8585/)
2021-03-30 16:10:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8585/?phpinfo=1> (referer: http://172.16.1.2:8585/)
2021-03-30 16:10:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://172.16.1.2:8585/uploads/> from <GET http://172.16.1.2:8585/uploads>
[*] Executing keep_alive..
2021-03-30 16:10:43 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8585/?lang=fr>
{'urls': ['http://172.16.1.2:8585/?lang=en', 'http://172.16.1.2:8585/?phpinfo=1', 'http://172.16.1.2:8585/phpmyadmin/', 'http://172.16.1.2:8585/uploads', 'http://172.16.1.2:8585/wordpress', 'http://172.16.1.2:8585/httpd-dav/', 'http://172.16.1.2:8585/phpmyadmin/', 'http://172.16.1.2:8585/sqlbuddy/', 'http://172.16.1.2:8585/webgrind/', 'http://www.wampserver.com', 'http://www.wampserver.com/en/donations.php', 'http://www.alterway.fr']}
2021-03-30 16:10:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://172.16.1.2:8585/phpmyadmin/>: HTTP status code is not handled or not allowed
2021-03-30 16:10:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://172.16.1.2:8585/wordpress/> from <GET http://172.16.1.2:8585/wordpress>
[*] Executing keep_alive..
2021-03-30 16:10:47 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8585/?phpinfo=1>
{'urls': ['http://www.php.net/', 'http://www.zend.com/', 'http://172.16.1.2:8585/index.php?=PHPB8B5F2A0-3C92-11d3-A3A9-4C7B08C10000']}
2021-03-30 16:10:50 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.wampserver.com': <GET http://www.wampserver.com>
2021-03-30 16:10:56 [scrapy.spidermiddlewares.offsite] DEBUG: Filtered offsite request to 'www.alterway.fr': <GET http://www.alterway.fr>
2021-03-30 16:10:56 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://172.16.1.2:8585/httpd-dav/> (referer: http://172.16.1.2:8585/)
2021-03-30 16:10:56 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://172.16.1.2:8585/sqlbuddy/> (referer: http://172.16.1.2:8585/)
2021-03-30 16:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8585/uploads/> (referer: http://172.16.1.2:8585/)
2021-03-30 16:10:56 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://172.16.1.2:8585/webgrind/> (referer: http://172.16.1.2:8585/)
2021-03-30 16:10:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://172.16.1.2:8585/httpd-dav/>: HTTP status code is not handled or not allowed
2021-03-30 16:10:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://172.16.1.2:8585/sqlbuddy/>: HTTP status code is not handled or not allowed
[*] Executing keep_alive..
2021-03-30 16:10:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8585/uploads/>
{'urls': ['http://172.16.1.2:8585/uploads/?C=N;O=D', 'http://172.16.1.2:8585/uploads/?C=M;O=A', 'http://172.16.1.2:8585/uploads/?C=S;O=A', 'http://172.16.1.2:8585/uploads/?C=D;O=A', 'http://172.16.1.2:8585/']}
2021-03-30 16:10:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:8585/wordpress/> (referer: http://172.16.1.2:8585/)
2021-03-30 16:10:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://172.16.1.2:8585/webgrind/>: HTTP status code is not handled or not allowed
[*] Executing keep_alive..
2021-03-30 16:10:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://172.16.1.2:8585/wordpress/>
{'urls': ['http://172.16.1.2:8585/wordpress/', 'http://172.16.1.2:8585/wordpress/#search-container', 'http://172.16.1.2:8585/wordpress/#content', 'http://172.16.1.2:8585/wordpress/index.php/king-of-hearts/', 'http://172.16.1.2:8585/wordpress/index.php/2016/09/26/hello-world/', 'http://172.16.1.2:8585/wordpress/index.php/2016/09/26/hello-world/', 'http://172.16.1.2:8585/wordpress/index.php/author/admin/', 'http://172.16.1.2:8585/wordpress/index.php/2016/09/26/hello-world/#respond', 'http://172.16.1.2:8585/wordpress/index.php/2016/09/26/hello-world/', 'http://172.16.1.2:8585/wordpress/index.php/2016/09/', 'http://172.16.1.2:8585/wordpress/index.php/category/uncategorized/', 'http://172.16.1.2:8585/wordpress/wp-login.php', 'http://172.16.1.2:8585/wordpress/index.php/feed/', 'http://172.16.1.2:8585/wordpress/index.php/comments/feed/', 'https://wordpress.org/', 'https://wordpress.org/', 'http://172.16.1.2:8585/wordpress/wp-includes/js/jquery/jquery.js?ver=1.12.4', 'http://172.16.1.2:8585/wordpress/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1', 'http://172.16.1.2:8585/wordpress/wp-content/themes/twentyfourteen/js/functions.js?ver=20150315', 'http://172.16.1.2:8585/wordpress/wp-includes/js/wp-embed.min.js?ver=4.6.1']}
2021-03-30 16:10:57 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:10:57 [scrapy.extensions.feedexport] INFO: Stored json feed (4 items) in: crawl_result/20210330161016_crawl_result.json
2021-03-30 16:10:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2741,
 'downloader/request_count': 11,
 'downloader/request_method_count/GET': 11,
 'downloader/response_bytes': 97568,
 'downloader/response_count': 11,
 'downloader/response_status_count/200': 5,
 'downloader/response_status_count/301': 2,
 'downloader/response_status_count/403': 3,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 1,
 'elapsed_time_seconds': 39.794786,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 10, 57, 707368),
 'httperror/response_ignored_count': 4,
 'httperror/response_ignored_status_count/403': 3,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 4,
 'log_count/DEBUG': 18,
 'log_count/INFO': 15,
 'memusage/max': 321011712,
 'memusage/startup': 321011712,
 'offsite/domains': 2,
 'offsite/filtered': 3,
 'request_depth_max': 1,
 'response_received_count': 9,
 'scheduler/dequeued': 11,
 'scheduler/dequeued/memory': 11,
 'scheduler/enqueued': 11,
 'scheduler/enqueued/memory': 11,
 'start_time': datetime.datetime(2021, 3, 30, 14, 10, 17, 912582)}
2021-03-30 16:10:57 [scrapy.core.engine] INFO: Spider closed (finished)
2021-03-30 16:10:58 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:10:58 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:10:58 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:10:59 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:10:59 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:10:59 [scrapy.extensions.telnet] INFO: Telnet Password: c438fc87b9d82232
2021-03-30 16:10:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_9200.log
2021-03-30 16:10:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:10:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:10:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:10:59 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:10:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:10:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:11:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://172.16.1.2:9200/> (referer: None)
2021-03-30 16:11:00 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:11:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 210,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 373,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.934181,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 11, 0, 900529),
 'log_count/DEBUG': 1,
 'log_count/INFO': 10,
 'memusage/max': 316731392,
 'memusage/startup': 316731392,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 3, 30, 14, 10, 59, 966348)}
2021-03-30 16:11:00 [scrapy.core.engine] INFO: Spider closed (finished)
[!] [crawl_result/20210330161058_crawl_result.json] is empty.
2021-03-30 16:11:01 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)
2021-03-30 16:11:01 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.8.5 (default, Jan 27 2021, 15:41:15) - [GCC 9.3.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.8.0-48-generic-x86_64-with-glibc2.29
2021-03-30 16:11:01 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2021-03-30 16:11:02 [tensorflow] DEBUG: Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
Using TensorFlow backend.
2021-03-30 16:11:02 [scrapy.crawler] INFO: Overridden settings:
{'CLOSESPIDER_ERRORCOUNT': '0',
 'CLOSESPIDER_ITEMCOUNT': '50',
 'CLOSESPIDER_PAGECOUNT': '50',
 'CLOSESPIDER_TIMEOUT': '300',
 'SPIDER_LOADER_WARN_ONLY': True}
2021-03-30 16:11:02 [scrapy.extensions.telnet] INFO: Telnet Password: 81e93117c4c60a8a
2021-03-30 16:11:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
[*] Save log to /home/ludovic/Test_Lab/machine_learning_security/DeepExploit/crawl_result/172.16.1.2_47001.log
2021-03-30 16:11:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-03-30 16:11:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-03-30 16:11:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2021-03-30 16:11:02 [scrapy.core.engine] INFO: Spider opened
2021-03-30 16:11:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-03-30 16:11:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
[*] Executing keep_alive..
2021-03-30 16:11:03 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://172.16.1.2:47001/> (referer: None)
2021-03-30 16:11:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://172.16.1.2:47001/>: HTTP status code is not handled or not allowed
2021-03-30 16:11:03 [scrapy.core.engine] INFO: Closing spider (finished)
2021-03-30 16:11:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 210,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 452,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 0.869259,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2021, 3, 30, 14, 11, 3, 813106),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/DEBUG': 1,
 'log_count/INFO': 11,
 'memusage/max': 317403136,
 'memusage/startup': 317403136,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2021, 3, 30, 14, 11, 2, 943847)}
2021-03-30 16:11:03 [scrapy.core.engine] INFO: Spider closed (finished)
[!] [crawl_result/20210330161101_crawl_result.json] is empty.
[!] Scramble target list.
[+] 1/1 Start analyzing: http://172.16.1.2:80/
[*] Executing keep_alive..
[!] Cutting response byte 1116923 to 10000.
[+] Analyzing gathered HTTP response.
[*] 1/109 Check tikiwiki using [(Powered by TikiWiki)]
[*] 2/109 Check wordpress using [<.*=(.*/wp-).*/.*>]
[*] 3/109 Check wordpress using [(<meta\s+content=[\"']WordPress).*>]
[*] 4/109 Check wordpress using [.*(Powered by WordPress)]
[*] 5/109 Check wordpress using [.*(://.*/xmlrpc.php)]
[*] 6/109 Check wordpress using [.*(WordPress ([0-9]+[\.0-9]*[\.0-9]*)).*]
[*] 7/109 Check wordpress using [.*(WordPress/([0-9]+[\.0-9]*[\.0-9]*)).*]
[*] 8/109 Check movabletype using [.*Movable Type.*(v=([0-9]+[\.0-9]*[\.0-9]*)).*]
[*] 9/109 Check movabletype using [<.*/(mt-.*)/.*>]
[*] Executing keep_alive..
[*] 10/109 Check movabletype using [(<.*/mt/.*>)]
[*] 11/109 Check movabletype using [(<meta\s+content=[\"']Movable Type).*>]
[*] 12/109 Check movabletype using [(<meta\s+content=[\"'].*www\.movabletype\.org).*>]
[*] 13/109 Check movabletype using [<center>(Powered by.*Movable Type\s+([0-9]+[\.0-9]*[\.0-9]*)).*</center>]
[*] 14/109 Check drupal using [.*(data-drupal-link-system-path)]
[*] 15/109 Check drupal using [.*(jQuery.extend\(Drupal.settings)]
[*] 16/109 Check drupal using [(<meta name=[\"']Generator[\"'] content=[\"']Drupal).*>]
[*] 17/109 Check drupal using [(<script\s+src=[\"']/core/misc/drupal).*>]
[*] 18/109 Check drupal using [(<script\s+data-drupal-selector=[\"']drupal-).*>]
[*] 19/109 Check drupal using [<script\s+src=[\"'](/core/misc/drupalSettingsLoader\.js\?v=([0-9]+[\.0-9]*[\.0-9]*)).*>]
[*] Executing keep_alive..
[*] 20/109 Check drupal using [<script\s+src=[\"'](/core/misc/drupal\.js\?v=([0-9]+[\.0-9]*[\.0-9]*)).*>]
[*] 21/109 Check drupal using [<script\s+src=[\"'](/core/misc/drupal\.init\.js\?v=([0-9]+[\.0-9]*[\.0-9]*)).*>]
[*] 22/109 Check drupal using [<script\s+src=[\"'](/themes/bootstrap/js/drupal\.bootstrap\.js).*>]
[*] 23/109 Check drupal using [.*(X-Drupal-.*Cache: MISS).*]
[*] 24/109 Check drupal using [.*(X-Drupal-Dynamic-.*Cache: MISS).*]
[*] 25/109 Check drupal using [.*(X-Generator: Drupal 7).*]
[*] 26/109 Check drupal using [.*(X-Generator: Drupal 8).*]
[*] 27/109 Check joomla using [<meta\s+(content=[\"']Joomla).*>]
[*] 28/109 Check joomla using [<script\s+(src=[\"']/templates/joomla/).*>]
[*] 29/109 Check joomla using [Set-Cookie:.*(jfcookie=.*;)]
[*] Executing keep_alive..
[*] 30/109 Check joomla using [(X-Content-Encoded-By:\s+Joomla!\s+([0-9]+[\.0-9]*[\.0-9]*)).*]
[*] 31/109 Check typo3 using [.*(This website is powered by TYPO3).*>]
[*] 32/109 Check typo3 using [.*(href="fileadmin/templates/).*>]
[*] 33/109 Check typo3 using [(<meta\s+content=[\"']TYPO3).*>]
[*] 34/109 Check typo3 using [(Set-Cookie: .*typo.*=[a-z0-9]{32});]
[*] 35/109 Check typo3 using [.*(TYPO[0-9]).*]
[*] 36/109 Check oscommerce using [(Set-Cookie: osCsid=.*);]
[*] 37/109 Check tomcat using [.*(Tomcat/([0-9]+[\.0-9]*[\.0-9]*))]
[*] 38/109 Check tomcat using [.*(Apache Tomcat User Guide)]
[*] 39/109 Check tomcat using [.*(Tomcat\s([0-9])\sServlet/JSP container)]
[*] Executing keep_alive..
[*] 40/109 Check tomcat using [.*(Tomcat\sServlet/JSP container)]
[*] 41/109 Check tomcat using [.*(JSP Samples)]
[*] 42/109 Check tomcat using [.*(Servlet Examples with Code)]
[*] 43/109 Check tomcat using [.*(Apache Tomcat User Guide)]
[*] 44/109 Check tomcat using [.*(KNOWN ISSUES IN THIS RELEASE)]
[*] 45/109 Check tomcat using [.*(Tomcat's administration web)]
[*] 46/109 Check struts using [.*(org\.apache\.struts\.taglib\.html\.TOKEN)]
[*] 47/109 Check coldfusion using [Set-Cookie.*(CFID=.*;)]
[*] 48/109 Check coldfusion using [Set-Cookie.*(CFTOKEN=.*;)]
[*] 49/109 Check coldfusion using [.*(ColdFusion Administrator)]
[*] Executing keep_alive..
[*] 50/109 Check coldfusion using [.*(ColdFusion Documentation)]
[*] 51/109 Check coldfusion using [.*(what_you_can_do_in_coldfusion_administrator)]
[*] 52/109 Check weblogic using [.*(WebLogic/([0-9]+[\.0-9]*[\.0-9]*))]
[*] 53/109 Check jboss using [X-Powered-By:.*(JBoss-([0-9]+[\.0-9]*[\.0-9]*))]
[*] 54/109 Check red_hat using [Server:.*(\(Red Hat\))]
[*] 55/109 Check red_hat using [Server:.*(\(Red Hat Enterprise linux\))]
[*] 56/109 Check ubuntu using [Server:.*(\(Ubuntu\))]
[*] 57/109 Check unix using [Server:.*(\(unix\))]
[*] 58/109 Check windows using [Server:.*(iis/1\.0)]
[*] 59/109 Check windows using [Server:.*(iis/2\.0)]
[*] Executing keep_alive..
[*] 60/109 Check windows using [Server:.*(iis/3\.0)]
[*] 61/109 Check windows using [Server:.*(iis/4\.0)]
[*] 62/109 Check windows using [Server:.*(iis/5\.0)]
[*] 63/109 Check windows using [Server:.*(iis/5\.1)]
[*] 64/109 Check windows using [Server:.*(iis/6\.0)]
[*] 65/109 Check windows using [Server:.*(iis/7\.0)]
[*] 66/109 Check windows using [Server:.*(iis/7\.5)]
[!] Find product=windows/*
[*] 67/109 Check windows using [Server:.*(iis/8\.0)]
[*] 68/109 Check windows using [Server:.*(iis/8\.5)]
[*] 69/109 Check windows using [Server:.*(\(win64\))]
[*] Executing keep_alive..
[*] 70/109 Check windows using [Server:.*(\(win32\))]
[*] 71/109 Check apache using [Server:.*(Apache/([0-9]+[\.0-9]*[\.0-9]*))]
[*] 72/109 Check apache using [Server:.*(Apache)[\s\r\n]]
[*] 73/109 Check apache using [.*(Apache/([0-9]+[\.0-9]*[\.0-9]*))]
[*] 74/109 Check apache using [.*(Test Page for Apache)]
[*] 75/109 Check apache using [.*(Apache HTTP Server[^D]*Documentation Project)]
[*] 76/109 Check apache using [.*(<title>Apache Status</title>)]
[*] 77/109 Check apache using [.*(Multi Language Custom Error Documents)]
[*] 78/109 Check apache using [.*(This file is generated from xml source)]
[*] 79/109 Check nginx using [Server:.*(nginx/([0-9]+[\.0-9]*[\.0-9]*))]
[*] Executing keep_alive..
[*] 80/109 Check nginx using [Server:.*(nginx)]
[*] 81/109 Check nginx using [.*(nginx/([0-9]+[\.0-9]*[\.0-9]*))]
[*] 82/109 Check iis using [Server:.*(Microsoft-IIS/([0-9]+\.[0-9]+))]
[!] Find product=iis/7.5
[*] 83/109 Check iis using [Server:.*(IIS/([0-9]+\.[0-9]+))]
[!] Find product=iis/7.5
[*] 84/109 Check iis using [Server:.*(IIS)]
[!] Find product=iis/*
[*] 85/109 Check iis using [.*(It works).*]
[*] 86/109 Check http using [(http/\d{1,2}\.\d{1,2}\.\d{1,2}|http/\d{1,2}\.\d{1,2}|http).*[\r\n]]
[*] 87/109 Check bigip using [Server:.*(bigip)]
[*] 88/109 Check php using [Server:.*(PHP/([0-9]+[\.0-9]*[\.0-9]*))]
[*] 89/109 Check php using [X-Powered-By:.*(PHP/([0-9]+[\.0-9]*[\.0-9]*))]
[*] Executing keep_alive..
[*] 90/109 Check php using [Set-Cookie:.*(PHPSESSID=.*;)]
[*] 91/109 Check php using [.*(PHP Credits)]
[*] 92/109 Check php using [.*(<title>phpinfo\(\))]
[*] 93/109 Check php using [.*(<title>phpinfo\(\)</title>)]
[*] 94/109 Check asp using [.*(X-AspNet-Version:.*([0-9]+[\.0-9]*[\.0-9]*))]
[*] 95/109 Check asp using [.*(X-AspNetMvc-Version:.*([0-9]+[\.0-9]*[\.0-9]*))]
[*] 96/109 Check asp using [Set-Cookie:.*(ASP\.NET_SessionId=.*;)]
[*] 97/109 Check asp using [.*(X-Powered-By:\s+ASP\.NET)]
[!] Find product=asp/*
[*] 98/109 Check python using [(python/\d{1,2}\.\d{1,2}\.\d{1,2}|python/\d{1,2}\.\d{1,2}|python).*[\r\n]]
[*] 99/109 Check phpmyadmin using [.*(phpMyAdmin ([0-9]+[\.0-9]*[\.0-9]*))]
[*] Executing keep_alive..
[*] 100/109 Check phpmyadmin using [.*<title>(phpMyAdmin).*]
[*] 101/109 Check phpmyadmin using [.*<title>(phpMyAdmin setup).*]
[*] 102/109 Check phpmyadmin using [.*<title>(phpMyAdmin.*[0-9])</title>.*]
[*] 103/109 Check phpmyadmin using [.*(phpmyadmin.svn.sourceforge.net/svnroot/phpmyadmin/trunk/phpMyAdmin/ChangeLog).*]
[*] 104/109 Check phpmyadmin using [.*(phpMyAdmin - ChangeLog).*]
[*] 105/109 Check squirrelmail using [.*(SquirrelMail version ([0-9]+))]
[*] 106/109 Check openssl using [Server:.*(OpenSSL/([0-9]+\.[0-9]+\.[0-9][a-z]))]
[*] 107/109 Check openssl using [Server:.*(OpenSSL/([0-9]+\.[0-9]+\.[0-9]))]
[*] 108/109 Check awstats using [.*(AWStats for domain).*]
[*] 109/109 Check upnp using [(upnp/\d{1,2}\.\d{1,2}\.\d{1,2}|upnp/\d{1,2}\.\d{1,2}|upnp).*[\r\n]]
[+] Analyzing gathered HTTP response using ML.
[*] Executing keep_alive..
[!] Product Not Found.
[+] Explore unnecessary contents.
[*] 1/68 Accessing : Status: 404, Url: http://172.16.1.2:80/server-status
[*] 2/68 Accessing : Status: 404, Url: http://172.16.1.2:80/error/README
[*] 3/68 Accessing : Status: 404, Url: http://172.16.1.2:80/icons/
[*] 4/68 Accessing : Status: 404, Url: http://172.16.1.2:80/icons/README
[*] 5/68 Accessing : Status: 404, Url: http://172.16.1.2:80/icons/small/README.txt
[*] 6/68 Accessing : Status: 404, Url: http://172.16.1.2:80/manual/
[*] 7/68 Accessing : Status: 404, Url: http://172.16.1.2:80/manual/images/
[*] 8/68 Accessing : Status: 404, Url: http://172.16.1.2:80/manual/style/
[*] 9/68 Accessing : Status: 404, Url: http://172.16.1.2:80/wp-login.php
[*] Executing keep_alive..
[*] 10/68 Accessing : Status: 404, Url: http://172.16.1.2:80/wp/wp-login.php
[*] 11/68 Accessing : Status: 404, Url: http://172.16.1.2:80/wp-admin/
[*] 12/68 Accessing : Status: 404, Url: http://172.16.1.2:80/wp/wp-admin
[*] 13/68 Accessing : Status: 404, Url: http://172.16.1.2:80/wp-content/
[*] 14/68 Accessing : Status: 404, Url: http://172.16.1.2:80/wp-includes/
[*] 15/68 Accessing : Status: 404, Url: http://172.16.1.2:80/wp-json/
[*] 16/68 Accessing : Status: 404, Url: http://172.16.1.2:80/wp-json/wp/v2/users
[*] 17/68 Accessing : Status: 404, Url: http://172.16.1.2:80/xmlrpc.php
[*] 18/68 Accessing : Status: 200, Url: http://172.16.1.2:80/?author=1
[+] Confirm string matching.

